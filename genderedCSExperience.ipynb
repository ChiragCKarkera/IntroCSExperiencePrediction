{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Model the dynamics of gender in intro CS\n",
    "## Using feature selection\n",
    "\n",
    "### Proposed Procedure\n",
    "\n",
    "\n",
    "1. Transform data to the numeric format\n",
    "2. Conduct simple scaling on the data\n",
    "3. Use **Random Forest Classifier** to do feature selection\n",
    "4. Feed those features into an **SVM**. Another option is just use a linear regression\n",
    "- Consider the RBF kernel K(x, y)\n",
    "- Use cross-validation to find the best parameter C and γ\n",
    "- Use the best parameter C and γ to train the whole training set\n",
    "- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pyplt\n",
    "import tools as tl\n",
    "import inputData\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "\n",
    "Let's go ahead and read in the student dataset first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "student_data = inputData.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494 male students, and 388 female students consented to participate in this study\n"
     ]
    }
   ],
   "source": [
    "student_data = student_data.query('gender == \"Female\" or gender == \"Male\"')\n",
    "student_data = student_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print '{:d}{:20}{:d}{:20}'.format(len(student_data.query('gender == \"Male\"')), ' male students, and ',\n",
    "                                  len(student_data.query('gender == \"Female\"')),\n",
    "                                  ' female students consented to participate in this study')\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the columns that aren't needed for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columnsNotNeeded = ['timestamp', 'consent','name', 'name_1', 'name_2', \n",
    "                    'morecs','snap_python','hiphop_d1','hiphop_d2','song_ct', 'major'] \n",
    "student_data.drop(columnsNotNeeded, axis=1, inplace=True)\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess feature columns\n",
    "\n",
    "There are several non-numeric columns that need to be converted! Many of them are simply `yes`/`no`, e.g. `prcs_2`. These can be reasonably converted into `1`/`0` (binary) values. For the columns whose values are `Nan`, I am going to convert these to `0`. \n",
    "\n",
    "\n",
    "**Note**: These generated columns are sometimes called _dummy variables_, and we will use the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) function to perform this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['Yes', 'No'], [1, 0])\n",
    "        # Note: This should change the data type for yes/no columns to int\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            # e.g. 'reason' => 'reason_class_Interested' , 'reason_class_Other'\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "        outX.fillna(0, inplace=True) # make sure all NaN <missing> values are set to 0\n",
    "\n",
    "    return outX\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (47):- ['atcs_1', 'atcs_2', 'atcs_3', 'atcs_4', 'atcs_5', 'atcs_6', 'atcs_7', 'atcs_8', 'atcs_9', 'atcsgender_1', 'atcsgender_2', 'atcsgender_3', 'atcsjob_1', 'atcsjob_2', 'atct_1', 'atct_2', 'atct_3', 'atct_4', 'atct_5', 'atct_6', 'atct_7', 'atct_8', 'blg_1', 'blg_2', 'blg_3', 'blg_4', 'classmtr', 'clet_1', 'clet_2', 'cltrcmp_1', 'cltrcmp_2', 'gender_Female', 'gender_Male', 'grade_B or above', 'grade_B or below', 'mtr_1', 'mtr_2', 'mtr_3', 'prcs_1', 'prcs_2', 'prcs_3', 'prcs_4', 'prcs_5', 'prepared', 'priorcs10', 'reason_class_Interested', 'reason_class_Other']\n"
     ]
    }
   ],
   "source": [
    "student_data = preprocess_features(student_data)\n",
    "print \"Processed feature columns ({}):- {}\".format(len(student_data.columns), list(student_data.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "Linearly scale each attribute to the range [−1, +1] or [0, 1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atcs_1</th>\n",
       "      <th>atcs_2</th>\n",
       "      <th>atcs_3</th>\n",
       "      <th>atcs_4</th>\n",
       "      <th>atcs_5</th>\n",
       "      <th>atcs_6</th>\n",
       "      <th>atcs_7</th>\n",
       "      <th>atcs_8</th>\n",
       "      <th>atcs_9</th>\n",
       "      <th>atcsgender_1</th>\n",
       "      <th>...</th>\n",
       "      <th>mtr_3</th>\n",
       "      <th>prcs_1</th>\n",
       "      <th>prcs_2</th>\n",
       "      <th>prcs_3</th>\n",
       "      <th>prcs_4</th>\n",
       "      <th>prcs_5</th>\n",
       "      <th>prepared</th>\n",
       "      <th>priorcs10</th>\n",
       "      <th>reason_class_Interested</th>\n",
       "      <th>reason_class_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     atcs_1  atcs_2  atcs_3  atcs_4  atcs_5  atcs_6  atcs_7  atcs_8  atcs_9  \\\n",
       "877    1.00    1.00    1.00    0.00    1.00    1.00    1.00    1.00    1.00   \n",
       "878    0.00    0.50    0.25    1.00    0.00    0.00    0.00    0.00    0.00   \n",
       "879    1.00    1.00    1.00    0.25    0.75    1.00    1.00    0.75    1.00   \n",
       "880    1.00    1.00    0.75    0.25    0.50    0.75    0.50    0.50    0.75   \n",
       "881    0.75    0.75    0.50    0.25    0.25    1.00    0.75    0.50    1.00   \n",
       "\n",
       "     atcsgender_1         ...          mtr_3  prcs_1  prcs_2  prcs_3  prcs_4  \\\n",
       "877             0         ...              1       1       1       1       1   \n",
       "878             0         ...              0       0       0       0       0   \n",
       "879             0         ...              0       1       1       0       1   \n",
       "880             0         ...              0       0       0       0       0   \n",
       "881             0         ...              0       0       0       0       0   \n",
       "\n",
       "     prcs_5  prepared  priorcs10  reason_class_Interested  reason_class_Other  \n",
       "877       1      1.00          0                        1                   0  \n",
       "878       0      0.00          0                        0                   1  \n",
       "879       1      1.00          0                        0                   0  \n",
       "880       0      0.00          0                        1                   0  \n",
       "881       1      0.25          0                        1                   0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df = student_data\n",
    "\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "#pd.DataFrame(scaler.fit_transform(student_data), columns=student_data.columns)\n",
    "\n",
    "student_data = df_scaled\n",
    "student_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "- Lets start with a few features first and see how they perform\n",
    "- This is where I should use human intuition and the qualitative research already done to pick features.\n",
    "\n",
    "So based on the research, I am going to pick items that measure *belonging* and *computational thinking*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "features_list = ['blg_1', 'blg_2', 'blg_3', 'blg_4', \n",
    "                 'atct_1', 'atct_2', 'atct_3', 'atct_4', 'atct_5', 'atct_6', 'atct_7', 'atct_8'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature values:-\n",
      "   blg_1  blg_2  blg_3  blg_4  atct_1  atct_2  atct_3  atct_4  atct_5  atct_6  \\\n",
      "0   0.75   0.25   0.50   0.50    0.75    0.75    0.75     1.0    0.50    0.75   \n",
      "1   0.25   0.75   0.00   0.00    0.50    0.50    0.50     0.5    0.00    0.25   \n",
      "2   0.50   0.00   0.50   0.50    0.75    0.75    1.00     1.0    0.75    0.75   \n",
      "3   0.50   0.50   0.50   0.75    0.75    0.75    1.00     1.0    0.75    0.75   \n",
      "4   0.75   0.25   0.25   0.50    0.75    1.00    1.00     0.5    0.00    0.75   \n",
      "\n",
      "   atct_7  atct_8  \n",
      "0    0.75    0.25  \n",
      "1    0.25    0.00  \n",
      "2    0.75    0.75  \n",
      "3    0.25    0.75  \n",
      "4    0.50    0.00  \n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: gender_Female, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Extract feature (X) and target (y) columns\n",
    "\n",
    "target_col = student_data['gender_Female']  #  column is the target/label\n",
    "feature_cols = pd.DataFrame(student_data, columns=features_list) \n",
    "\n",
    "y_all = target_col  # corresponding targets/labels\n",
    "# Make sure to delete the 'gender_Male' column from the training data\n",
    "_ = student_data.pop('gender_Male')\n",
    "X_all = feature_cols\n",
    "\n",
    "print \"\\nFeature values:-\"\n",
    "print X_all.head()  \n",
    "print y_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Visualization\n",
    "- As we can see the dataset is unbalanced, we have more males than females.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEZCAYAAABmTgnDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZpbJycLMzDI5WZiZWab/BuW2mf8bk0n4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1141879d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_all.plot.hist()\n",
    "\n",
    "_= pyplt.xlabel('Value')\n",
    "_= pyplt.title('Histogram of y_all')\n",
    "_= pyplt.legend(loc='upper center', shadow=True, fontsize='medium')\n",
    "_= pyplt.yticks(np.arange(0, 1000, 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Sklearn Function\n",
    "Another approach I want to try is using sklearns feature selection function `SelectPercentile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):- ['atcs_1', 'atcs_2', 'atcs_3', 'atcs_4', 'atcs_5', 'atcs_6', 'atcs_7', 'atcs_8', 'atcs_9', 'atcsgender_1', 'atcsgender_2', 'atcsgender_3', 'atcsjob_1', 'atcsjob_2', 'atct_1', 'atct_2', 'atct_3', 'atct_4', 'atct_5', 'atct_6', 'atct_7', 'atct_8', 'blg_1', 'blg_2', 'blg_3', 'blg_4', 'classmtr', 'clet_1', 'clet_2', 'cltrcmp_1', 'cltrcmp_2', 'grade_B or above', 'grade_B or below', 'mtr_1', 'mtr_2', 'mtr_3', 'prcs_1', 'prcs_2', 'prcs_3', 'prcs_4', 'prcs_5', 'prepared', 'priorcs10', 'reason_class_Interested', 'reason_class_Other']\n"
     ]
    }
   ],
   "source": [
    "## Make sure we drop gender_Female from the table, otherwise we will be including the labeled data\n",
    "\n",
    "student_data = student_data.drop('gender_Female', axis=1)  # feature values for all students\n",
    "print \"Feature column(s):-\", list(student_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "# lets choose the top 10% of features that yeild the most infomation\n",
    "\n",
    "selector = SelectPercentile(f_classif, percentile=15)\n",
    "selector.fit(student_data, target_col)\n",
    "\n",
    "\n",
    "features_transformed = selector.transform(student_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features have been reduced from 45 to 7\n"
     ]
    }
   ],
   "source": [
    "print\"{:20}{:d}{:4}{:d}\".format(\"Features have been reduced from \", student_data.shape[1],\n",
    "                               \" to\", features_transformed.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Split Data into training and testing set\n",
    "\n",
    "#### Pro Tip:\n",
    "When dealing with the new data set it is good practice to assess its specific characteristics and implement the cross validation technique tailored on those very characteristics, in our case there are two main elements:\n",
    "\n",
    "- Our dataset is slightly unbalanced. (There are more passing students than on passing students)\n",
    "\n",
    "We could take advantage of K-fold cross validation to exploit small data sets. Even though in this case it might not be necessary, should we have to deal with heavily unbalance datasets, we could address the unbalanced nature of our data set using Stratified K-Fold and Stratified Shuffle Split Cross validation, as stratification is preserving the preserving the percentage of samples for each class.\n",
    "\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedKFold.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, decide how many training vs test samples you want\n",
    "num_all = features_transformed.shape[0] #student_data.shape[0]  # same as len(student_data)\n",
    "num_train = int(num_all * 0.75)  # about 75% of the data\n",
    "num_test = num_all - num_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use new features as input to classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = features_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully shuffled and split the data!\n",
      "Training set: 661 samples\n",
      "Test set: 221 samples\n"
     ]
    }
   ],
   "source": [
    "# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\n",
    "\n",
    "# Test shuffle_split_data\n",
    "try:\n",
    "    X_train, y_train, X_test, y_test = tl.shuffle_split_data(X_all, y_all, num_train)\n",
    "    print \"Successfully shuffled and split the data!\"\n",
    "except:\n",
    "    print \"Something went wrong with shuffling and splitting the data.\"\n",
    "\n",
    "\n",
    "print \"Training set: {} samples\".format(X_train.shape[0])\n",
    "print \"Test set: {} samples\".format(X_test.shape[0])\n",
    "# Note: If you need a validation set, extract it from within training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Validating\n",
    "\n",
    "#### Dictionary of models to run\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "models = {'DecisionTree': tree.DecisionTreeClassifier(),\n",
    "          'SVC': svm.SVC(),\n",
    "          'RandomForest': RandomForestClassifier()\n",
    "         }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               RandomForestClassifier\n",
      "                                    Training set size\n",
      "                              200\t400\t600\n",
      "-------------------------------------------------------\n",
      "Training time (secs)          0.020\t0.022\t0.020\n",
      "Prediction time (secs)        0.001\t0.001\t0.001\n",
      "F1 score for training set     0.927\t0.909\t0.966\n",
      "F1 score for test set         0.564\t0.557\t0.492\n",
      "\n",
      "\n",
      "                               DecisionTreeClassifier\n",
      "                                    Training set size\n",
      "                              200\t400\t600\n",
      "-------------------------------------------------------\n",
      "Training time (secs)          0.001\t0.001\t0.000\n",
      "Prediction time (secs)        0.000\t0.000\t0.000\n",
      "F1 score for training set     0.964\t0.933\t0.989\n",
      "F1 score for test set         0.562\t0.564\t0.558\n",
      "\n",
      "\n",
      "                                                  SVC\n",
      "                                    Training set size\n",
      "                              200\t400\t600\n",
      "-------------------------------------------------------\n",
      "Training time (secs)          0.003\t0.006\t0.001\n",
      "Prediction time (secs)        0.001\t0.002\t0.001\n",
      "F1 score for training set     0.538\t0.499\t0.721\n",
      "F1 score for test set         0.443\t0.485\t0.579\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "scores = [accuracy_score, precision_score, recall_score, f1_score]\n",
    "score_list = []\n",
    "model_score_list = []\n",
    "model_name_list = []\n",
    "prntLatex = 0 # key to print table optimized for insertion in Latex document.\n",
    "    \n",
    "for model_name, clf in models.iteritems():\n",
    "# Fit model to the training data, and predict labels (for both training and test sets), and measure the F1 score. \n",
    "    tl.train_classifier(clf, X_train, y_train)\n",
    "    train_time, F1_score_train, F1_score_test, prediction_time_test = tl.train_predict(clf, \n",
    "                                                                        X_train, y_train, X_test, y_test)\n",
    "    tl.makeTable(clf, X_train, y_train, X_test, y_test, prntLatex)\n",
    "\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         RandomForestClassifier         \n",
      "                           Actual Gender\n",
      "Predicted                Female    Male      \n",
      "               Female    81.000    30.000    \n",
      "               Male      56.000    54.000    \n",
      "\n",
      "\n",
      "\n",
      "         DecisionTreeClassifier         \n",
      "                           Actual Gender\n",
      "Predicted                Female    Male      \n",
      "               Female    76.000    35.000    \n",
      "               Male      53.000    57.000    \n",
      "\n",
      "\n",
      "\n",
      "                  SVC                   \n",
      "                           Actual Gender\n",
      "Predicted                Female    Male      \n",
      "               Female    93.000    18.000    \n",
      "               Male      69.000    41.000    \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, clf in models.iteritems():\n",
    "    # Create confusion matrix\n",
    "    tl.makeConfusionMatrix(clf, X_test, y_test)\n",
    "    print '\\n\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Model\n",
    "## Proposed Procedure\n",
    "\n",
    "1. Transform data to the format of an SVM package\n",
    "2. Conduct simple scaling on the data\n",
    "- Consider the RBF kernel K(x, y)\n",
    "- Use cross-validation to find the best parameter C and γ\n",
    "- Use the best parameter C and γ to train the whole training set\n",
    "- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Fine-tune your model and report the best F1 score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "# Build a stratified shuffle object because of unbalanced data\n",
    "ssscv = StratifiedShuffleSplit(y_train, n_iter=10, test_size=0.3)\n",
    "\n",
    "# For an initial search, a logarithmic grid with basis\n",
    "# 10 is often helpful. Using a basis of 2, a finer\n",
    "# tuning can be achieved but at a much higher cost.\n",
    "\n",
    "C_range = 10. ** np.arange(-3, 5)\n",
    "gamma_range = 2. ** np.arange(-5, 1)\n",
    "kernel_list = ['rbf']\n",
    "\n",
    "param_grid = dict(kernel=kernel_list, gamma=gamma_range, C=C_range)\n",
    "\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "grid = GridSearchCV(svm.SVC(), param_grid=param_grid, cv=ssscv, scoring=f1_scorer)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"The best classifier is: \", grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"{:>33}\".format(grid.__class__.__name__)\n",
    "print \"-\"*35\n",
    "\n",
    "print \"{:30}{:.3f}\".format('F1 score for training set' ,grid.score(X_train, y_train))\n",
    "print \"{:30}{:.3f}\".format('F1 score for test set' ,grid.score(X_test, y_test))\n",
    "print \"\\nBest params: {}\".format( grid.best_params_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid_scores_ contains parameter settings and scores\n",
    "score_dict = grid.grid_scores_\n",
    "\n",
    "# We extract just the scores\n",
    "scores = [x[1] for x in score_dict]\n",
    "scores = np.array(scores).reshape(len(C_range), len(gamma_range))\n",
    "\n",
    "# Make a nice figure\n",
    "pyplt.figure(figsize=(10, 6))\n",
    "pyplt.subplots_adjust(left=0.15, right=0.95, bottom=0.15, top=0.95)\n",
    "pyplt.imshow(scores, interpolation='nearest', cmap=pyplt.cm.coolwarm)\n",
    "pyplt.title('Gamma versus C for SVM')\n",
    "pyplt.xlabel('gamma')\n",
    "pyplt.ylabel('C')\n",
    "pyplt.colorbar()\n",
    "pyplt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "pyplt.yticks(np.arange(len(C_range)), C_range)\n",
    "pyplt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bias $C$ to correct for class imbalance\n",
    "\n",
    "As previously stated, there are more examples of student success than failure. As such, the optimal learner for this problem is one that can still generate reasonable classification given the unbalanced dataset. SVMs have a method of *biasing* the soft-margin constant, $C$, to correct for class imbalances. \n",
    "- The solution is to assign a different soft-margin constant to each class.\n",
    "\n",
    "## Pipelining\n",
    "You could actually go well beyond grid search and implement ‘pipelines’ where the whole machine learning process becomes 'grid-searchable' and you can parameterize and search the whole process though cross validation.\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "And yes you can try out several algorithms automatically as well too! Watch out though this is pretty advanced stuff, here is a great, informative, top notch tutorial from Zac Sewart!\n",
    "http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection \n",
    "### Random Forest Classifier\n",
    "\n",
    "Random forests are a popular method for feature ranking, since they are so easy to apply: in general they require very little feature engineering and parameter tuning and mean decrease impurity is exposed in most random forest libraries. But they come with their own gotchas, especially when data interpretation is concerned. With correlated features, strong features can end up with low scores and the method can be biased towards variables with many categories. As long as the gotchas are kept in mind, there really is no reason not to try them out on your data. [Diving into data blog](http://blog.datadive.net/selecting-good-features-part-iii-random-forests/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Lets find important features\n",
    "## Feature ranking\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import operator\n",
    "\n",
    "def getImportantFeatures(n=1, topNFeatures=5):\n",
    "    \"\"\"Retrieve top N features.\n",
    "\n",
    "    Keyword arguments:\n",
    "    n -- the number of times you want to run the classifier, knowing that it randomizes its seed (int)\n",
    "    topNFeatures -- top n features of interest (int)\n",
    "    \"\"\"\n",
    "    names = X_train.columns\n",
    "    rf = RandomForestClassifier()\n",
    "    featuresSortedByScore = list()\n",
    "\n",
    "    for i in range(n):\n",
    "        rf.fit(X_train, np.ravel(y_train))\n",
    "        featuresSortedByScore.append(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True))\n",
    "        \n",
    "    # Get top features through tally\n",
    "\n",
    "    myTopFeature = {}\n",
    "    for i in range (len(featuresSortedByScore)):\n",
    "        for j in range (topNFeatures):\n",
    "            if featuresSortedByScore[i][j][1] not in myTopFeature.keys():\n",
    "                myTopFeature[featuresSortedByScore[i][j][1]] = 1\n",
    "            else:\n",
    "                myTopFeature[featuresSortedByScore[i][j][1]] += 1\n",
    "\n",
    "\n",
    "    return sorted(myTopFeature.items(), key=operator.itemgetter(1), reverse=True)[:topNFeatures]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "topNFeatures = 10\n",
    "newFeatures = getImportantFeatures(n, topNFeatures)\n",
    "\n",
    "for i in range(len(newFeatures)):\n",
    "    print newFeatures[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newFeatures\n",
    "newCols = []\n",
    "\n",
    "for col, _ in newFeatures:\n",
    "    newCols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = student_data[newCols]\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
