{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Model the dynamics of gender in intro CS\n",
    "## Using feature selection\n",
    "\n",
    "### Proposed Procedure\n",
    "\n",
    "\n",
    "1. Transform data to the numeric format\n",
    "2. Conduct simple scaling on the data\n",
    "3. Use **Random Forest Classifier** to do feature selection\n",
    "4. Feed those features into an **SVM**. Another option is just use a linear regression\n",
    "- Consider the RBF kernel K(x, y)\n",
    "- Use cross-validation to find the best parameter C and γ\n",
    "- Use the best parameter C and γ to train the whole training set\n",
    "- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pyplt\n",
    "import tools as tl\n",
    "import inputData\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "\n",
    "Let's go ahead and read in the student dataset first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = inputData.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494 male students, and 388 female students consented to participate in this study\n"
     ]
    }
   ],
   "source": [
    "data = data.query('gender == \"Female\" or gender == \"Male\"')\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print '{:d}{:20}{:d}{:20}'.format(len(data.query('gender == \"Male\"')), ' male students, and ',\n",
    "                                  len(data.query('gender == \"Female\"')),\n",
    "                                  ' female students consented to participate in this study')\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the columns that aren't needed for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columnsNotNeeded = ['timestamp', 'consent','name', 'name_1', 'name_2', \n",
    "                    'morecs','snap_python','hiphop_d1','hiphop_d2','song_ct', 'major'] \n",
    "data.drop(columnsNotNeeded, axis=1, inplace=True)\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess feature columns\n",
    "\n",
    "There are several non-numeric columns that need to be converted! Many of them are simply `yes`/`no`, e.g. `prcs_2`. These can be reasonably converted into `1`/`0` (binary) values. For the columns whose values are `Nan`, I am going to convert these to `0`. \n",
    "\n",
    "\n",
    "**Note**: These generated columns are sometimes called _dummy variables_, and we will use the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) function to perform this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['Yes', 'No'], [1, 0])\n",
    "        # Note: This should change the data type for yes/no columns to int\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            # e.g. 'reason' => 'reason_class_Interested' , 'reason_class_Other'\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "        outX.fillna(0, inplace=True) # make sure all NaN <missing> values are set to 0\n",
    "\n",
    "    return outX\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (47):- ['atcs_1', 'atcs_2', 'atcs_3', 'atcs_4', 'atcs_5', 'atcs_6', 'atcs_7', 'atcs_8', 'atcs_9', 'atcsgender_1', 'atcsgender_2', 'atcsgender_3', 'atcsjob_1', 'atcsjob_2', 'atct_1', 'atct_2', 'atct_3', 'atct_4', 'atct_5', 'atct_6', 'atct_7', 'atct_8', 'blg_1', 'blg_2', 'blg_3', 'blg_4', 'classmtr', 'clet_1', 'clet_2', 'cltrcmp_1', 'cltrcmp_2', 'gender_Female', 'gender_Male', 'grade_B or above', 'grade_B or below', 'mtr_1', 'mtr_2', 'mtr_3', 'prcs_1', 'prcs_2', 'prcs_3', 'prcs_4', 'prcs_5', 'prepared', 'priorcs10', 'reason_class_Interested', 'reason_class_Other']\n"
     ]
    }
   ],
   "source": [
    "data = preprocess_features(data)\n",
    "print \"Processed feature columns ({}):- {}\".format(len(data.columns), list(data.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "Linearly scale each attribute to the range [−1, +1] or [0, 1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atcs_1</th>\n",
       "      <th>atcs_2</th>\n",
       "      <th>atcs_3</th>\n",
       "      <th>atcs_4</th>\n",
       "      <th>atcs_5</th>\n",
       "      <th>atcs_6</th>\n",
       "      <th>atcs_7</th>\n",
       "      <th>atcs_8</th>\n",
       "      <th>atcs_9</th>\n",
       "      <th>atcsgender_1</th>\n",
       "      <th>...</th>\n",
       "      <th>mtr_3</th>\n",
       "      <th>prcs_1</th>\n",
       "      <th>prcs_2</th>\n",
       "      <th>prcs_3</th>\n",
       "      <th>prcs_4</th>\n",
       "      <th>prcs_5</th>\n",
       "      <th>prepared</th>\n",
       "      <th>priorcs10</th>\n",
       "      <th>reason_class_Interested</th>\n",
       "      <th>reason_class_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     atcs_1  atcs_2  atcs_3  atcs_4  atcs_5  atcs_6  atcs_7  atcs_8  atcs_9  \\\n",
       "877    1.00    1.00    1.00    0.00    1.00    1.00    1.00    1.00    1.00   \n",
       "878    0.00    0.50    0.25    1.00    0.00    0.00    0.00    0.00    0.00   \n",
       "879    1.00    1.00    1.00    0.25    0.75    1.00    1.00    0.75    1.00   \n",
       "880    1.00    1.00    0.75    0.25    0.50    0.75    0.50    0.50    0.75   \n",
       "881    0.75    0.75    0.50    0.25    0.25    1.00    0.75    0.50    1.00   \n",
       "\n",
       "     atcsgender_1         ...          mtr_3  prcs_1  prcs_2  prcs_3  prcs_4  \\\n",
       "877           0.0         ...            1.0     1.0     1.0     1.0     1.0   \n",
       "878           0.0         ...            0.0     0.0     0.0     0.0     0.0   \n",
       "879           0.0         ...            0.0     1.0     1.0     0.0     1.0   \n",
       "880           0.0         ...            0.0     0.0     0.0     0.0     0.0   \n",
       "881           0.0         ...            0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "     prcs_5  prepared  priorcs10  reason_class_Interested  reason_class_Other  \n",
       "877     1.0      1.00        0.0                      1.0                 0.0  \n",
       "878     0.0      0.00        0.0                      0.0                 1.0  \n",
       "879     1.0      1.00        0.0                      0.0                 0.0  \n",
       "880     0.0      0.00        0.0                      1.0                 0.0  \n",
       "881     1.0      0.25        0.0                      1.0                 0.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df = data\n",
    "\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "data = df_scaled\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Feature Relevance\n",
    "One interesting thought to consider is if one (or more) of the 47 features is actually relevant for understanding the impact of gender on belonging. We can make this determination quite easily by training a supervised regression learner on a subset of the data with one feature removed, and then score how well that model can predict the removed feature.\n",
    "\n",
    "- Based on domain knowledge, we will limit the features to three dimensions:\n",
    "    - atcs: Attitudes about CS competency.\n",
    "    - blg: Sense of belonging in the CS classroom.\n",
    "    - atct: Understanding of computational thinking.\n",
    "    \n",
    "This reduces the set of features from 47 to 21.   \n",
    "We are going to use the feature **`'blg_1'`** as our target \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atcs = ['atcs_1', 'atcs_2', 'atcs_3', 'atcs_4', 'atcs_5', \n",
    "        'atcs_6', 'atcs_7', 'atcs_8', 'atcs_9']# self reported attitude about CS competency\n",
    "atct = ['atct_1', 'atct_2', 'atct_3', 'atct_4', \n",
    "        'atct_5', 'atct_6', 'atct_7', 'atct_8'] # Self reported attitudes about computational thinking\n",
    "blg = ['blg_1', 'blg_2', 'blg_3', 'blg_4'] # Sense of belonging in the class room\n",
    "clet = ['clet_1', 'clet_2'] # Social implications and ethics\n",
    "\n",
    "itemDimensions = {}\n",
    "itemDimensions['atcs'] = atcs\n",
    "itemDimensions['atct'] = atct\n",
    "itemDimensions['blg'] = blg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_lists = [\n",
    "itemDimensions['atcs'], \n",
    "itemDimensions['blg'],\n",
    "itemDimensions['atct']\n",
    "]\n",
    "\n",
    "flattened = [val for sublist in list_of_lists for val in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atct_1         I am good at solving a problem by thinking about similar problems I’ve solved before.\n",
      "atct_2         I have good research skills.\n",
      "atct_3         I am good at using online search tools.\n",
      "atct_4         I am persistent at solving puzzles or logic problems.\n",
      "atct_5         I know how to write computer programs\n",
      "atct_6         I am good at building things.\n",
      "atct_7         I’m good at ignoring irrelevant details to solve a problem.\n",
      "atct_8         I know how to write a computer program to solve a problem.\n",
      "atcs_1         I like to use computer science to solve problems.\n",
      "atcs_2         I can learn to understand computing concepts.\n",
      "atcs_3         I can achieve good grades (C or better) in computing courses.\n",
      "atcs_4         I do not like using computer science to solve problems.\n",
      "atcs_5         I am confident that I can solve problems by using computation\n",
      "atcs_6         The challenge of solving problems using computer science appeals to me.\n",
      "atcs_7         I am comfortable with learning computing concepts.\n",
      "atcs_8         I am confident about my abilities with regards to computer science.\n",
      "atcs_9         I do think I can learn to understand computing concepts.\n",
      "blg_1          In this class, I feel I belong.\n",
      "blg_2          In this class, I feel awkward and out of place.\n",
      "blg_3          In this class, I feel like my ideas count.\n",
      "blg_4          In this class, I feel like I matter.\n"
     ]
    }
   ],
   "source": [
    "for key in itemDimensions:\n",
    "    inputData.describeData(itemDimensions[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atcs_1</th>\n",
       "      <th>atcs_2</th>\n",
       "      <th>atcs_3</th>\n",
       "      <th>atcs_4</th>\n",
       "      <th>atcs_5</th>\n",
       "      <th>atcs_6</th>\n",
       "      <th>atcs_7</th>\n",
       "      <th>atcs_8</th>\n",
       "      <th>atcs_9</th>\n",
       "      <th>blg_1</th>\n",
       "      <th>...</th>\n",
       "      <th>blg_3</th>\n",
       "      <th>blg_4</th>\n",
       "      <th>atct_1</th>\n",
       "      <th>atct_2</th>\n",
       "      <th>atct_3</th>\n",
       "      <th>atct_4</th>\n",
       "      <th>atct_5</th>\n",
       "      <th>atct_6</th>\n",
       "      <th>atct_7</th>\n",
       "      <th>atct_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   atcs_1  atcs_2  atcs_3  atcs_4  atcs_5  atcs_6  atcs_7  atcs_8  atcs_9  \\\n",
       "0     0.5    0.75    1.00    0.50    0.75    0.75    0.75    0.50    0.75   \n",
       "1     0.0    0.00    0.00    1.00    0.00    0.00    0.00    0.00    0.25   \n",
       "2     1.0    1.00    1.00    0.00    1.00    1.00    1.00    1.00    1.00   \n",
       "3     1.0    0.75    0.75    0.00    0.75    0.75    0.75    1.00    1.00   \n",
       "4     0.5    0.50    0.75    0.25    0.50    0.75    1.00    0.25    0.75   \n",
       "\n",
       "   blg_1   ...    blg_3  blg_4  atct_1  atct_2  atct_3  atct_4  atct_5  \\\n",
       "0   0.75   ...     0.50   0.50    0.75    0.75    0.75     1.0    0.50   \n",
       "1   0.25   ...     0.00   0.00    0.50    0.50    0.50     0.5    0.00   \n",
       "2   0.50   ...     0.50   0.50    0.75    0.75    1.00     1.0    0.75   \n",
       "3   0.50   ...     0.50   0.75    0.75    0.75    1.00     1.0    0.75   \n",
       "4   0.75   ...     0.25   0.50    0.75    1.00    1.00     0.5    0.00   \n",
       "\n",
       "   atct_6  atct_7  atct_8  \n",
       "0    0.75    0.75    0.25  \n",
       "1    0.25    0.25    0.00  \n",
       "2    0.75    0.75    0.75  \n",
       "3    0.75    0.25    0.75  \n",
       "4    0.75    0.50    0.00  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data[flattened].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared score on training data:  1.0\n",
      "r-squared score on testing data:  -0.00373767757691\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of the DataFrame, using the 'drop' function to drop the given feature\n",
    "\n",
    "new_data_target = data['blg_1']\n",
    "new_data = data.drop('blg_1', axis=1, inplace=False)\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets using the given feature as the target\n",
    "from sklearn import cross_validation\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(new_data, new_data_target, \n",
    "                                                                     test_size=0.25, random_state=42)\n",
    "\n",
    "# Create a decision tree regressor and fit it to the training set\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressor_score = {}\n",
    "iteration_limit = 100\n",
    "\n",
    "# Repeate the regression 100x to smooth out variation in the decision tree formation and train/test splits\n",
    "for i in range(iteration_limit):\n",
    "    \n",
    "    regressor = DecisionTreeRegressor(random_state = 42)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    score = regressor.score(X_test, y_test)\n",
    "    if 'train' in regressor_score.keys():\n",
    "        regressor_score['train'] += regressor.score(X_train, y_train)\n",
    "        regressor_score['test'] += regressor.score(X_test, y_test)\n",
    "    else:\n",
    "        regressor_score['train'] = regressor.score(X_train, y_train)\n",
    "        regressor_score['test'] = regressor.score(X_test, y_test)\n",
    "        \n",
    "        \n",
    "# Report the score of the prediction using the testing set\n",
    "print \"r-squared score on training data: \", regressor_score['train']/iteration_limit\n",
    "print \"r-squared score on testing data: \", regressor_score['test']/iteration_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "- Lets start with a few features first and see how they perform\n",
    "- This is where I should use human intuition and the qualitative research already done to pick features.\n",
    "\n",
    "So based on the research, I am going to pick items that measure *belonging* and *computational thinking*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "features_list = ['blg_1', 'blg_2', 'blg_3', 'blg_4', \n",
    "                 'atct_1', 'atct_2', 'atct_3', 'atct_4', 'atct_5', 'atct_6', 'atct_7', 'atct_8'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract feature (X) and target (y) columns\n",
    "\n",
    "target_col = data['gender_Female']  #  column is the target/label\n",
    "feature_cols = pd.DataFrame(data, columns=features_list) \n",
    "\n",
    "y_all = target_col  # corresponding targets/labels\n",
    "# Make sure to delete the 'gender_Male' column from the training data\n",
    "_ = data.pop('gender_Male')\n",
    "X_all = feature_cols\n",
    "\n",
    "print \"\\nFeature values:-\"\n",
    "print X_all.head()  \n",
    "print y_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Visualization\n",
    "- As we can see the dataset is unbalanced, we have more males than females.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_all.plot.hist()\n",
    "\n",
    "_= pyplt.xlabel('Value')\n",
    "_= pyplt.title('Histogram of y_all')\n",
    "_= pyplt.legend(loc='upper center', shadow=True, fontsize='medium')\n",
    "_= pyplt.yticks(np.arange(0, 1000, 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Sklearn Function\n",
    "Another approach I want to try is using sklearns feature selection function `SelectPercentile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Make sure we drop gender_Female from the table, otherwise we will be including the labeled data\n",
    "\n",
    "data = data.drop('gender_Female', axis=1)  # feature values for all students\n",
    "print \"Feature column(s):-\", list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "# lets choose the top 10% of features that yeild the most infomation\n",
    "\n",
    "selector = SelectPercentile(f_classif, percentile=15)\n",
    "selector.fit(data, target_col)\n",
    "\n",
    "\n",
    "features_transformed = selector.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print\"{:20}{:d}{:4}{:d}\".format(\"Features have been reduced from \", data.shape[1],\n",
    "                               \" to\", features_transformed.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Split Data into training and testing set\n",
    "\n",
    "#### Pro Tip:\n",
    "When dealing with the new data set it is good practice to assess its specific characteristics and implement the cross validation technique tailored on those very characteristics, in our case there are two main elements:\n",
    "\n",
    "- Our dataset is slightly unbalanced. (There are more passing students than on passing students)\n",
    "\n",
    "We could take advantage of K-fold cross validation to exploit small data sets. Even though in this case it might not be necessary, should we have to deal with heavily unbalance datasets, we could address the unbalanced nature of our data set using Stratified K-Fold and Stratified Shuffle Split Cross validation, as stratification is preserving the preserving the percentage of samples for each class.\n",
    "\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedKFold.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, decide how many training vs test samples you want\n",
    "num_all = features_transformed.shape[0] #data.shape[0]  # same as len(data)\n",
    "num_train = int(num_all * 0.75)  # about 75% of the data\n",
    "num_test = num_all - num_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use new features as input to classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = features_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\n",
    "\n",
    "# Test shuffle_split_data\n",
    "try:\n",
    "    X_train, y_train, X_test, y_test = tl.shuffle_split_data(X_all, y_all, num_train)\n",
    "    print \"Successfully shuffled and split the data!\"\n",
    "except:\n",
    "    print \"Something went wrong with shuffling and splitting the data.\"\n",
    "\n",
    "\n",
    "print \"Training set: {} samples\".format(X_train.shape[0])\n",
    "print \"Test set: {} samples\".format(X_test.shape[0])\n",
    "# Note: If you need a validation set, extract it from within training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Validating\n",
    "\n",
    "#### Dictionary of models to run\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "models = {'DecisionTree': tree.DecisionTreeClassifier(),\n",
    "          'SVC': svm.SVC(),\n",
    "          'RandomForest': RandomForestClassifier()\n",
    "         }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "scores = [accuracy_score, precision_score, recall_score, f1_score]\n",
    "score_list = []\n",
    "model_score_list = []\n",
    "model_name_list = []\n",
    "prntLatex = 0 # key to print table optimized for insertion in Latex document.\n",
    "    \n",
    "for model_name, clf in models.iteritems():\n",
    "# Fit model to the training data, and predict labels (for both training and test sets), and measure the F1 score. \n",
    "    tl.train_classifier(clf, X_train, y_train)\n",
    "    train_time, F1_score_train, F1_score_test, prediction_time_test = tl.train_predict(clf, \n",
    "                                                                        X_train, y_train, X_test, y_test)\n",
    "    tl.makeTable(clf, X_train, y_train, X_test, y_test, prntLatex)\n",
    "\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model_name, clf in models.iteritems():\n",
    "    # Create confusion matrix\n",
    "    tl.makeConfusionMatrix(clf, X_test, y_test)\n",
    "    print '\\n\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Model\n",
    "## Proposed Procedure\n",
    "\n",
    "1. Transform data to the format of an SVM package\n",
    "2. Conduct simple scaling on the data\n",
    "- Consider the RBF kernel K(x, y)\n",
    "- Use cross-validation to find the best parameter C and γ\n",
    "- Use the best parameter C and γ to train the whole training set\n",
    "- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Fine-tune your model and report the best F1 score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "# Build a stratified shuffle object because of unbalanced data\n",
    "ssscv = StratifiedShuffleSplit(y_train, n_iter=10, test_size=0.3)\n",
    "\n",
    "# For an initial search, a logarithmic grid with basis\n",
    "# 10 is often helpful. Using a basis of 2, a finer\n",
    "# tuning can be achieved but at a much higher cost.\n",
    "\n",
    "C_range = 10. ** np.arange(-3, 5)\n",
    "gamma_range = 2. ** np.arange(-5, 1)\n",
    "kernel_list = ['rbf']\n",
    "\n",
    "param_grid = dict(kernel=kernel_list, gamma=gamma_range, C=C_range)\n",
    "\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "grid = GridSearchCV(svm.SVC(), param_grid=param_grid, cv=ssscv, scoring=f1_scorer)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"The best classifier is: \", grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"{:>33}\".format(grid.__class__.__name__)\n",
    "print \"-\"*35\n",
    "\n",
    "print \"{:30}{:.3f}\".format('F1 score for training set' ,grid.score(X_train, y_train))\n",
    "print \"{:30}{:.3f}\".format('F1 score for test set' ,grid.score(X_test, y_test))\n",
    "print \"\\nBest params: {}\".format( grid.best_params_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid_scores_ contains parameter settings and scores\n",
    "score_dict = grid.grid_scores_\n",
    "\n",
    "# We extract just the scores\n",
    "scores = [x[1] for x in score_dict]\n",
    "scores = np.array(scores).reshape(len(C_range), len(gamma_range))\n",
    "\n",
    "# Make a nice figure\n",
    "pyplt.figure(figsize=(10, 6))\n",
    "pyplt.subplots_adjust(left=0.15, right=0.95, bottom=0.15, top=0.95)\n",
    "pyplt.imshow(scores, interpolation='nearest', cmap=pyplt.cm.coolwarm)\n",
    "pyplt.title('Gamma versus C for SVM')\n",
    "pyplt.xlabel('gamma')\n",
    "pyplt.ylabel('C')\n",
    "pyplt.colorbar()\n",
    "pyplt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "pyplt.yticks(np.arange(len(C_range)), C_range)\n",
    "pyplt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bias $C$ to correct for class imbalance\n",
    "\n",
    "As previously stated, there are more examples of student success than failure. As such, the optimal learner for this problem is one that can still generate reasonable classification given the unbalanced dataset. SVMs have a method of *biasing* the soft-margin constant, $C$, to correct for class imbalances. \n",
    "- The solution is to assign a different soft-margin constant to each class.\n",
    "\n",
    "## Pipelining\n",
    "You could actually go well beyond grid search and implement ‘pipelines’ where the whole machine learning process becomes 'grid-searchable' and you can parameterize and search the whole process though cross validation.\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "And yes you can try out several algorithms automatically as well too! Watch out though this is pretty advanced stuff, here is a great, informative, top notch tutorial from Zac Sewart!\n",
    "http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection \n",
    "### Random Forest Classifier\n",
    "\n",
    "Random forests are a popular method for feature ranking, since they are so easy to apply: in general they require very little feature engineering and parameter tuning and mean decrease impurity is exposed in most random forest libraries. But they come with their own gotchas, especially when data interpretation is concerned. With correlated features, strong features can end up with low scores and the method can be biased towards variables with many categories. As long as the gotchas are kept in mind, there really is no reason not to try them out on your data. [Diving into data blog](http://blog.datadive.net/selecting-good-features-part-iii-random-forests/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Lets find important features\n",
    "## Feature ranking\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import operator\n",
    "\n",
    "def getImportantFeatures(n=1, topNFeatures=5):\n",
    "    \"\"\"Retrieve top N features.\n",
    "\n",
    "    Keyword arguments:\n",
    "    n -- the number of times you want to run the classifier, knowing that it randomizes its seed (int)\n",
    "    topNFeatures -- top n features of interest (int)\n",
    "    \"\"\"\n",
    "    names = X_train.columns\n",
    "    rf = RandomForestClassifier()\n",
    "    featuresSortedByScore = list()\n",
    "\n",
    "    for i in range(n):\n",
    "        rf.fit(X_train, np.ravel(y_train))\n",
    "        featuresSortedByScore.append(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True))\n",
    "        \n",
    "    # Get top features through tally\n",
    "\n",
    "    myTopFeature = {}\n",
    "    for i in range (len(featuresSortedByScore)):\n",
    "        for j in range (topNFeatures):\n",
    "            if featuresSortedByScore[i][j][1] not in myTopFeature.keys():\n",
    "                myTopFeature[featuresSortedByScore[i][j][1]] = 1\n",
    "            else:\n",
    "                myTopFeature[featuresSortedByScore[i][j][1]] += 1\n",
    "\n",
    "\n",
    "    return sorted(myTopFeature.items(), key=operator.itemgetter(1), reverse=True)[:topNFeatures]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "topNFeatures = 10\n",
    "newFeatures = getImportantFeatures(n, topNFeatures)\n",
    "\n",
    "for i in range(len(newFeatures)):\n",
    "    print newFeatures[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newFeatures\n",
    "newCols = []\n",
    "\n",
    "for col, _ in newFeatures:\n",
    "    newCols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = data[newCols]\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
