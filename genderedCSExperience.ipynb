{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Model the dynamics of gender in intro CS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('tools/')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pyplt\n",
    "import seaborn as sns\n",
    "import tools\n",
    "import inputData\n",
    "   \n",
    "pyplt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "\n",
    "Let's go ahead and read in the student dataset first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = inputData.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494 male students, and 388 female students consented to participate in this study\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.query('gender == \"Female\" or gender == \"Male\"')\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print '{:d}{:20}{:d}{:20}'.format(len(dataset.query('gender == \"Male\"')), ' male students, and ',\n",
    "                                  len(dataset.query('gender == \"Female\"')),\n",
    "                                  ' female students consented to participate in this study')\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UC Berkeley Intro CS Student dataset\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:\n",
      "\n",
      "Number of Instances:882\n",
      "\n",
      "Attribute Information (in order):\n",
      "Self reported attitudes about CS\n",
      "- atcs_1 I like to use computer science to solve problems.\n",
      "- atcs_2 I can learn to understand computing concepts.\n",
      "- atcs_3 I can achieve good grades (C or better) in computing courses.\n",
      "- atcs_4 I do not like using computer science to solve problems.\n",
      "- atcs_5 I am confident that I can solve problems by using computation.\n",
      "- atcs_6 The challenge of solving problems using computer science appeals to me.\n",
      "- atcs_7 I am comfortable with learning computing concepts.\n",
      "- atcs_8 I am confident about my abilities with regards to computer science.\n",
      "- atcs_9 I do think I can learn to understand computing concepts.\n",
      "\n",
      "Gendered belief about CS ability\n",
      "- atcsgender_1 Women are less capable of success in CS than men.\n",
      "- atcsgender_2 Women are smarter than men.\n",
      "- atcsgender_3 Men have better math and science abilities than women.\n",
      "\n",
      "Career driven beliefs about CS\n",
      "- atcsjob_1 Knowledge of computing will allow me to secure a good job.\n",
      "- atcsjob_2 My career goals do not require that I learn computing skills.\n",
      "\n",
      "Self reported attitudes about computational thinking\n",
      "- atct_1 I am good at solving a problem by thinking about similar problems I have solved before.\n",
      "- atct_2 I have good research skills.\n",
      "- atct_3 I am good at using online search tools.\n",
      "- atct_4 I am persistent at solving puzzles or logic problems.\n",
      "- atct_5 I know how to write computer programs.\n",
      "- atct_6 I am good at building things.\n",
      "- atct_7 I am good at ignoring irrelevant details to solve a problem.\n",
      "- atct_8 I know how to write a computer program to solve a problem.\n",
      "\n",
      "Self reported attitudes about CS class belonging\n",
      "- blg_1 In this class, I feel I belong.\n",
      "- blg_2 In this class, I feel awkward and out of place.\n",
      "- blg_3 In this class, I feel like my ideas count.\n",
      "- blg_4 In this class, I feel like I matter.\n",
      "\n",
      "Self reported beliefs about collegiality\n",
      "- clet_1 I work well in teams.\n",
      "- clet_2 I think about the ethical, legal, and social implications of computing.\n",
      "- cltrcmp_1 I am comfortable interacting with peers from different backgrounds than my own (based on race, sexuality, income, and so on.)\n",
      "- cltrcmp_2 I have good cultural competence, or the ability to interact effectively with people from diverse backgrounds.\n",
      "\n",
      "Demographics\n",
      "- gender Could I please know your gender\n",
      "\n",
      "CS mentors and role models\n",
      "- mtr_1 Before I came to UC Berkeley, I knew people who have careers in Computer Science.\n",
      "- mtr_2 There are people with careers in Computer Science who look like me.\n",
      "- mtr_3 I have role models within the Computer Science field that look like me.\n",
      "\n",
      "Prior collegiate CS exposure\n",
      "- prcs_1 Did you take a CS course in High School?\n",
      "- prcs_2 Did you have any exposure to Computer Science before UC Berkeley?\n",
      "- prcs_3 Did a family member introduce you to Computer Science?\n",
      "- prcs_4 Did you have a close family member who is a Computer Scientist or is affiliated with computing industry?\n",
      "- prcs_5 Did your high school offer AP CS?\n",
      "\n",
      "Missing Attribute Values: None\n",
      "\n",
      "Creator: Omoju Miller\n"
     ]
    }
   ],
   "source": [
    "inputData.DESCR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "### Preprocess feature columns\n",
    "To prepare our data for classification, we need to devise a scheme to transform all features into numeric data. This dataset as several non-numeric columns that need converting. Many of them are simply `yes`/`no`, e.g. `prcs_2`. We can reasonably convert these into `1`/`0` (binary) values. For the columns whose values are `Nan`, we will convert these to `0`. \n",
    "\n",
    "\n",
    "**Note**: These generated columns are sometimes called _dummy variables_, and we will use the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) function to perform this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['Yes', 'No'], [1, 0])\n",
    "        # Note: This should change the data type for yes/no columns to int\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            # e.g. 'reason' => 'reason_class_Interested' , 'reason_class_Other'\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "        outX.fillna(0, inplace=True) # make sure all NaN <missing> values are set to 0\n",
    "\n",
    "    return outX\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = preprocess_features(dataset)\n",
    "print \"Processed feature columns ({}):- {}\".format(len(dataset.columns), list(dataset.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess feature columns - Rename columns\n",
    "\n",
    "There are some columns that have spaces in their names, these makes it difficult for the tree plotting algorithms that we will be using later to graph these features. As a result, we will change these spaces to hypens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.rename(columns = {'grade_B or above':'grade_B_or_above'}, inplace = True)\n",
    "dataset.rename(columns = {'grade_B or below':'grade_B_or_below'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "Linearly scale each attribute to the range [0, 1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(dataset), columns=dataset.columns)\n",
    "dataset = df_scaled\n",
    "dataset.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features and labels \n",
    "\n",
    "Extract feature (X) and target (y) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_col = dataset['gender_Female']  #  column is the target/label \n",
    "y = target_col  # corresponding targets/labels\n",
    "\n",
    "print \"\\nLabel values:-\"\n",
    "print y.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = dataset.drop(['gender_Female', 'gender_Male'], axis=1, inplace=False)\n",
    "\n",
    "print \"\\nFeature values:-\"\n",
    "print X.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Make sure we drop the target from the table, otherwise we will be including the labeled data\n",
    "\n",
    "print \"Feature column(s):-\", list(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine if classes are balanced\n",
    "- As we can see the dataset is unbalanced, we have more males than females.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.plot.hist()\n",
    "\n",
    "_= pyplt.xlabel('Value')\n",
    "_= pyplt.title('Histogram of Target Class')\n",
    "_= pyplt.legend(loc='upper center', shadow=True, fontsize='medium')\n",
    "_= pyplt.yticks(np.arange(0, 1000, 100))\n",
    "pyplt.savefig('report/figures/targetClass.pdf', dpi=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation\n",
    "We will use principal component analysis (PCA) to draw conclusions about the underlying structure of the data. Since using PCA on a dataset calculates the dimensions which best maximize variance, we will find which compound combinations of features best describe students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Apply PCA by fitting the good data with the same number of dimensions as features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_data = dataset.drop(['gender_Female', 'gender_Male'], axis=1, inplace=False)\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(pca_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Explained variance\n",
    "\n",
    "\n",
    "fig, ax = pyplt.subplots()\n",
    "\n",
    "_= pyplt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "_= pyplt.title('Explained Variance v. Number of Principal Components')\n",
    "_= pyplt.xlabel('number of components')\n",
    "_= pyplt.ylabel('cumulative explained variance')\n",
    "_= pyplt.show()\n",
    "\n",
    "fig.savefig('report/figures/explainedVariance.pdf', format='pdf', dpi=100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "X_pca = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_pca = pd.DataFrame(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, decide how many training vs test samples you want\n",
    "num_all = X.shape[0]  # same as len(student_data)\n",
    "num_train = 662  # about 75% of the data\n",
    "num_test = num_all - num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "\n",
    "\n",
    "def shuffle_split_data(X, y):\n",
    "    \"\"\" Shuffles and splits data into 75% training and 25% testing subsets,\n",
    "        then returns the training and testing subsets. \"\"\"\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, \n",
    "                                                                        train_size=num_train, random_state=42)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Return the training and testing data subsets\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    X_train, y_train, X_test, y_test = shuffle_split_data(X, y)\n",
    "    print \"Successfully shuffled and split the data!\"\n",
    "except:\n",
    "    print \"Something went wrong with shuffling and splitting the data.\"\n",
    "\n",
    "\n",
    "print \"Training set: {} samples\".format(X_train.shape[0])\n",
    "print \"Test set: {} samples\".format(X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_pca_train, y_pca_train, X_pca_test, y_pca_test = shuffle_split_data(X_pca, y)\n",
    "print \"Training set: {} samples\".format(X_pca_train.shape[0])\n",
    "print \"Test set: {} samples\".format(X_pca_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Validating\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created four separate tranches to investigate the data:\n",
    "- All features\n",
    "- A reduced dataset of features\n",
    "- PCA transformed features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X_train\n",
    "\n",
    "seed = 342 # For reproducability\n",
    "np.random.seed(seed)\n",
    "folds = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.learning_curve import validation_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "models = {\n",
    "          'XGBoost': XGBClassifier(),\n",
    "          'DecisionTree': tree.DecisionTreeClassifier(),\n",
    "          'SVC': svm.SVC(),\n",
    "          'RandomForest': RandomForestClassifier()\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model_name, model in models.iteritems():\n",
    "    print model_name\n",
    "    kfold = StratifiedKFold(y_train, n_folds=folds, random_state=seed)\n",
    "    results = cross_val_score(model, X, y_train, cv=kfold)\n",
    "    print(\"Training data accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100)), '\\n'\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Features_test = X_test\n",
    "\n",
    "for model_name, model in models.iteritems():\n",
    "    print model_name\n",
    "    # make predictions for test data\n",
    "    model.fit(X, y_train)\n",
    "    y_pred = model.predict(Features_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Testing data prediction accuracy: %.2f%%\" % (accuracy * 100.0)), '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select XGBoost classifier\n",
    "- Generate Features from XGBoost classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "from xgboost import plot_importance\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_importance(model)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(14, 8)\n",
    "fig.savefig('report/figures/feature_importance_xgb.pdf', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = xgb.to_graphviz(model, rankdir='LR')\n",
    "g.render('report/figures/X_graph.gv', view=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on a reduced set of features\n",
    "- We will reduce the number of features used based on feature importance given by xgboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract feature (X) and target (y) columns\n",
    "\n",
    "columnsToModel = [\n",
    "    'atcsgender_2', 'clet_2', 'atcsjob_2', 'atct_6', 'prepared',\n",
    "    'atcs_6', 'atct_5', 'atct_3', 'atcsjob_1', 'blg_1', 'atcsgender_3',\n",
    "    'atct_7', 'atct_4', 'clet_1', 'atct_8', 'atcs_5', 'atcsgender_1',\n",
    "    'cltrcmp_1', 'cltrcmp_2', 'blg_4']\n",
    "\n",
    "X_all_Reduced = X_train[columnsToModel]\n",
    "\n",
    "\n",
    "print \"\\nFeature values:-\"\n",
    "print X_all_Reduced.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "print \"Training: \", model.__class__.__name__\n",
    "kfold = StratifiedKFold(y_train, n_folds=folds, random_state=seed)\n",
    "results = cross_val_score(model, X_all_Reduced, y_train, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100)), '\\n'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Features_test = X_test[columnsToModel]\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_all_Reduced, y_train)\n",
    "y_pred = model.predict(Features_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Testing data prediction accuracy: %.2f%%\" % (accuracy * 100.0)), '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_all_Reduced, y_train)\n",
    "g = xgb.to_graphviz(model, rankdir='LR')\n",
    "g.render('report/figures/X_all_Reduced_graph.gv', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "print \"Training: \", model.__class__.__name__\n",
    "kfold = StratifiedKFold(y_pca_train, n_folds=folds, random_state=seed)\n",
    "results = cross_val_score(model, X_pca_train, y_pca_train, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100)), '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_pca_train, y_pca_train)\n",
    "y_pred = model.predict(X_pca_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_pca_test, predictions)\n",
    "print(\"Testing data prediction accuracy: %.2f%%\" % (accuracy * 100.0)), '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal choices of parameters as taken from Xgboost With Python ebook\n",
    "\n",
    "- Number of Trees (`n_estimators`) set to a fixed value between 100 and 1000, depending on the dataset size.\n",
    "- Learning Rate (`learnin_rate`) simplified to the ratio: [2 to 10]/trees, depending on the trees number of trees.\n",
    "- Row Sampling (`subsample`) grid searched values in the range [0.5, 0.75, 1.0].\n",
    "- Column Sampling (`colsample` bytree and maybe colsample bylevel) grid searched values in the range [0.4, 0.6, 0.8, 1.0].\n",
    "- Min Leaf Weight (`min_child_weight`) simplified to the ratio 3/rare_events , where rare events rare events is the percentage of rare event observations in the dataset.\n",
    "- Tree Size (`max_depth`) grid searched values in the rage [4, 6, 8, 10].\n",
    "- Min Split Gain (`gamma`) fixed with a value of zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "\n",
    "X = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "default_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 1,\n",
    "    'learning_rate': 0.3\n",
    "}\n",
    "\n",
    "\n",
    "n_estimators_range = np.linspace(1, 200, 10).astype('int') \n",
    "\n",
    "# Build a stratified shuffle object because of unbalanced data\n",
    "folds = 50\n",
    "ssscv = StratifiedShuffleSplit(y_train, folds, random_state=seed)\n",
    "\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    XGBClassifier(**default_params),\n",
    "    X, y_train,\n",
    "    param_name = 'n_estimators',\n",
    "    param_range = n_estimators_range,\n",
    "    cv=ssscv,\n",
    "    scoring='accuracy'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Show the validation curve plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6), dpi=100)\n",
    "\n",
    "plt.title(\"Validation Curve with XGBoost (eta = 0.3)\")\n",
    "plt.xlabel(\"number of trees\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.4, 1.1)\n",
    "\n",
    "plt.plot(n_estimators_range,\n",
    "             train_scores_mean,\n",
    "             label=\"Training score\",\n",
    "             color=\"r\")\n",
    "\n",
    "plt.plot(n_estimators_range,\n",
    "             test_scores_mean, \n",
    "             label=\"Cross-validation score\",\n",
    "             color=\"g\")\n",
    "\n",
    "plt.fill_between(n_estimators_range, \n",
    "                 train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, \n",
    "                 alpha=0.2, color=\"r\")\n",
    "\n",
    "plt.fill_between(n_estimators_range,\n",
    "                 test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std,\n",
    "                 alpha=0.2, color=\"g\")\n",
    "\n",
    "plt.axhline(y=1, color='k', ls='dashed')\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "i = np.argmax(test_scores_mean)\n",
    "print(\"Best cross-validation result ({0:.2f}) obtained for {1} trees\".format(test_scores_mean[i], \n",
    "                                                                             n_estimators_range[i]))\n",
    "\n",
    "fig.savefig('report/figures/varianceCurve_1.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plot we can draw the following conclusions:\n",
    "- training score keeps growing while adding new trees, but from a certain point CV score is fixed\n",
    "- variance is lowest, and bias is high for less than 25 trees,\n",
    "- we can see that the model is quite stable keeping variance fixed when increasing it's complexity   \n",
    "\n",
    "We can assume that the trade-off for our model will be met at n_estimators = 50. The variance is still to big.\n",
    "\n",
    "\n",
    "Tweak parameters\n",
    "- To reduce a variance:  \n",
    "    - each tree we will use 70% randomly chosen samples\n",
    "    - 60% randomly chosen features   \n",
    "    \n",
    "- To decrease the bias (bigger accuracy):\n",
    "    - Add an extra level to each tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 2, # changed\n",
    "    'learning_rate': 0.3,\n",
    "    'colsample_bytree': 0.6, # added\n",
    "    'subsample': 0.7 # added\n",
    "}\n",
    "\n",
    "n_estimators_range = np.linspace(1, 200, 10).astype('int')\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    XGBClassifier(**default_params),\n",
    "    X, y_train,\n",
    "    param_name = 'n_estimators',\n",
    "    param_range = n_estimators_range,\n",
    "    cv=ssscv,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6), dpi=100)\n",
    "\n",
    "plt.title(\"Validation Curve with XGBoost (eta = 0.3)\")\n",
    "plt.xlabel(\"number of trees\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.4, 1.1)\n",
    "plt.plot(n_estimators_range,\n",
    "             train_scores_mean,\n",
    "             label=\"Training score\",\n",
    "             color=\"r\")\n",
    "\n",
    "plt.plot(n_estimators_range,\n",
    "             test_scores_mean, \n",
    "             label=\"Cross-validation score\",\n",
    "             color=\"g\")\n",
    "\n",
    "plt.fill_between(n_estimators_range, \n",
    "                 train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, \n",
    "                 alpha=0.2, color=\"r\")\n",
    "\n",
    "plt.fill_between(n_estimators_range,\n",
    "                 test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std,\n",
    "                 alpha=0.2, color=\"g\")\n",
    "\n",
    "plt.axhline(y=1, color='k', ls='dashed')\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "i = np.argmax(test_scores_mean)\n",
    "print(\"Best cross-validation result ({0:.2f}) obtained for {1} trees\".format(test_scores_mean[i], \n",
    "                                                                             n_estimators_range[i]))\n",
    "fig.savefig('report/figures/varianceCurve_2.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "            'learning_rate': [0.2222, 0.4444, 0.6666, 0.8888],\n",
    "            'max_depth': [4, 6, 8, 10],\n",
    "            'n_estimators': range(100, 1100, 100),\n",
    "            'colsample_bytree': [0.6],\n",
    "            'subsample':[0.7]\n",
    "}\n",
    "\n",
    "params_fixed = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print '_'*20, 'Tuning XGBoost', '_'*20\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=XGBClassifier(**params_fixed),\n",
    "    param_grid=params_grid,\n",
    "    cv=ssscv,\n",
    "    scoring='accuracy')\n",
    "grid.fit(X, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Best accuracy obtained: {0}\".format(grid.best_score_)\n",
    "print \"Parameters:\"\n",
    "for key, value in grid.best_params_.items():\n",
    "    print \"\\t{}: {}\".format(key, value)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Features_test = X_test\n",
    "\n",
    "\n",
    "model = grid.best_estimator_\n",
    "\n",
    "# make predictions for test data\n",
    "model.fit(X, y_train)\n",
    "y_pred = model.predict(Features_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save model to file\n",
    "pickle.dump(model, open(\"genderedCSExperience.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X, y_train)\n",
    "g = xgb.to_graphviz(model, num_trees=2, rankdir='LR')\n",
    "g.render('report/figures/Tuned_model_graph.gv', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputData.describeData(itemDimensions['atct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
