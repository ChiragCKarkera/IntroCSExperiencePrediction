{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Factors that Predict Intro CS Experience Based on Gender\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "With this project, the problem I am interested in investigating is the gendered experience of the two CS classes in the study. Using machine learning algorithms, I want to identify the leading indicators of the experience broken down by gender in introductory CS at an elite research university like Berkeley.\n",
    "\n",
    "To solve this problem, I will undertake the following course of action:\n",
    "1. Explore the dataset.\n",
    "    - Usually, I would explore the dataset to ensure its integrity and understand the context. But in this case, I will skip this step since I designed the study and collected the data, as such, I am well versed of the context. Further, I have done previous work on this dataset, so I know its boundaries.\n",
    "2. Identify features that may be used. \n",
    "    - If possible, engineer features that might provide greater discrimination.\n",
    "3. With the understanding that this a `classification` task, explore a couple of classifiers that might be well suited for the problem at hand.\n",
    "4. Once a classifier has been selected, tune it for optimality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from __future__ import division\n",
    "import sys\n",
    "sys.path.append('tools/')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tools\n",
    "\n",
    "   \n",
    "# Graphing Libraries\n",
    "import matplotlib.pyplot as pyplt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the dataset\n",
    "\n",
    "Let's go ahead and read in the student dataset. There are two functions that support this dataset:\n",
    "- `dataLookUp(surveyItemCode)` This function take a string that is coded survey item. For example if you execute `dataLookUp(atcs_1)`, it prints out the corresponding survey question, I like to use computer science to solve problems. \n",
    "- `dataDescr()` This function gives you a general introduction to the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = tools.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tools.dataDescr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = dataset.query('gender == \"Female\" or gender == \"Male\"') #load rows with binary gender\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print '{:d}{:20}{:d}{:20}'.format(len(dataset.query('gender == \"Male\"')), ' male students, and ',\n",
    "                                  len(dataset.query('gender == \"Female\"')),\n",
    "                                  ' female students consented to participate in this study')\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "### Preprocess feature columns\n",
    "To prepare the data for classification, I need to devise a scheme to transform all features into numeric data. This dataset as several non-numeric columns that need converting. Many of them are simply `yes`/`no`, e.g. `prcs_2`. I can reasonably convert these into `1`/`0` (binary) values. For the columns whose values are `Nan`, I will convert these to `0`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['Yes', 'No'], [1, 0])\n",
    "        # Note: This should change the data type for yes/no columns to int\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            # e.g. 'reason' => 'reason_class_Interested' , 'reason_class_Other'\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "        outX.fillna(0, inplace=True) # make sure all NaN <missing> values are set to 0\n",
    "\n",
    "    return outX\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = preprocess_features(dataset)\n",
    "print \"Processed feature columns ({}):- {}\".format(len(dataset.columns), list(dataset.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess feature columns - Rename columns\n",
    "\n",
    "There are some columns that have spaces in their names, these makes it difficult for the tree plotting algorithms that we will be using later to graph these features. As a result, we will change these spaces to hypens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.rename(columns = {'grade_B or above':'grade_B_or_above'}, inplace = True)\n",
    "dataset.rename(columns = {'grade_B or below':'grade_B_or_below'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "Linearly scale each attribute to the range [0, 1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(dataset), columns=dataset.columns)\n",
    "dataset = df_scaled\n",
    "dataset.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Distribution\n",
    "\n",
    "Create the dimension that we are interested in investigating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtr = ['mtr_1', 'mtr_2', 'mtr_3'] # CS Mentors\n",
    "prcs = ['prcs_1', 'prcs_2', 'prcs_3', 'prcs_4', 'prcs_5'] # Prior CS Exposure\n",
    "atcs = ['atcs_1', 'atcs_2', 'atcs_3', 'atcs_5', 'atcs_4', \n",
    "        'atcs_6', 'atcs_7', 'atcs_8', 'atcs_9']# self reported attitude about CS competency\n",
    "atct = ['atct_1', 'atct_2', 'atct_3', 'atct_4', \n",
    "        'atct_5', 'atct_6', 'atct_7', 'atct_8'] # Self reported attitudes about computational thinking\n",
    "blg = ['blg_1', 'blg_2', 'blg_3', 'blg_4'] # Sense of belonging in the class room\n",
    "clet = ['clet_1', 'clet_2'] # Social implications and ethics\n",
    "atcsgender = ['atcsgender_1', 'atcsgender_2', 'atcsgender_3'] \n",
    "atcsjob = ['atcsjob_1', 'atcsjob_2'] \n",
    "cltrcmp = ['cltrcmp_1', 'cltrcmp_2'] # Culutral competency\n",
    "priorcs10 = 'priorcs10' # had taken CS10 prior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing Data\n",
    "\n",
    "For the majority of this plots, we can see that they are not normally distributed. Most of the data is either skewed to the left or skewed to the right. This lets us know that we can not rely of descriptive statistics like the mean to make sense of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[atcs].plot(kind='kde')\n",
    "\n",
    "x = [-0.5, 0.0, 0.5, 1.0, 1.5]\n",
    "labels = [\"\", \"Strongly Disagree\", \"Neutral\", \"Strongly Agree\" , \"\"]\n",
    "pyplt.xticks(x, labels)\n",
    "\n",
    "pyplt.xlabel('SURVEY RESPONSES')\n",
    "pyplt.title('DENSITY ESTIMATION OF COMPUTER SCIENCE ABILITY')\n",
    "pyplt.legend(loc='upper right', shadow=True, fontsize='medium')\n",
    "pyplt.savefig('report/figures/atcs_kde.pdf', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[atcs].quantile(0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[atct].plot(kind='kde')\n",
    "\n",
    "x = [-0.5, 0.0, 0.5, 1.0, 1.5]\n",
    "labels = [\"\", \"Strongly Disagree\", \"Neutral\", \"Strongly Agree\" , \"\"]\n",
    "pyplt.xticks(x, labels)\n",
    "\n",
    "pyplt.xlabel('SURVEY RESPONSES')\n",
    "pyplt.title('DENSITY ESTIMATION OF COMPUTATIONAL THINKING ABILITY')\n",
    "pyplt.legend(loc='upper right', shadow=True, fontsize='medium')\n",
    "pyplt.savefig('report/figures/atct_kde.pdf', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[atct].quantile(0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[blg].plot(kind='kde')\n",
    "\n",
    "x = [-0.5, 0.0, 0.5, 1.0, 1.5]\n",
    "labels = [\"\", \"Strongly Disagree\", \"Neutral\", \"Strongly Agree\" , \"\"]\n",
    "pyplt.xticks(x, labels)\n",
    "\n",
    "pyplt.xlabel('SURVEY RESPONSES')\n",
    "pyplt.title('DENSITY ESTIMATION OF BELONGING')\n",
    "pyplt.legend(loc='upper right', shadow=True, fontsize='medium')\n",
    "pyplt.savefig('report/figures/blg_kde.pdf', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[blg].quantile(.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[atcsgender].describe().ix['50%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[atcsgender].plot(kind='kde')\n",
    "\n",
    "x = [-0.5, 0.0, 0.5, 1.0, 1.5]\n",
    "labels = [\"\", \"Strongly Disagree\", \"Neutral\", \"Strongly Agree\" , \"\"]\n",
    "pyplt.xticks(x, labels)\n",
    "\n",
    "pyplt.xlabel('SURVEY RESPONSES')\n",
    "pyplt.title('DENSITY ESTIMATION OF ATCSGENDER')\n",
    "pyplt.legend(loc='upper center', shadow=True, fontsize='medium')\n",
    "pyplt.savefig('report/figures/atcsgender_kde.pdf', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[atcsgender].quantile(.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tools.dataLookUp('atcsgender_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, these variables have fair variability in their distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features and labels \n",
    "\n",
    "Extract feature (X) and target (y) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_col = dataset['gender_Female']  #  column is the target/label \n",
    "y = target_col  # corresponding targets/labels\n",
    "\n",
    "print \"\\nLabel values:-\"\n",
    "print y.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = dataset.drop(['gender_Female', 'gender_Male'], axis=1, inplace=False)\n",
    "\n",
    "print \"\\nFeature values:-\"\n",
    "print X.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Make sure we drop the target from the table, otherwise we will be including the labeled data\n",
    "\n",
    "print \"Feature column(s):-\", list(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine if classes are balanced\n",
    "- As we can see the dataset is unbalanced, we have more males than females.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.plot.hist()\n",
    "\n",
    "pyplt.grid(False)\n",
    "_= pyplt.xlabel('VALUE OF TARGET LABEL')\n",
    "_= pyplt.ylabel('COUNT')\n",
    "_= pyplt.title('HISTOGRAM OF TARGET CLASS')\n",
    "_= pyplt.legend(loc='upper center', shadow=True, fontsize='medium')\n",
    "_= pyplt.yticks(np.arange(0, 700, 100))\n",
    "pyplt.savefig('report/figures/targetClass.pdf', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_male = y.tolist().count(0)\n",
    "num_female = y.tolist().count(1)\n",
    "\n",
    "\n",
    "print \"number of males in data\", num_male\n",
    "print \"number of females in data\", num_female\n",
    "\n",
    "\n",
    "print \"ration of males to females {}\".format(num_male/ num_female)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, decide how many training vs test samples you want\n",
    "num_all = X.shape[0]  # same as len(student_data)\n",
    "num_train = 662  # about 75% of the data\n",
    "num_test = num_all - num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "\n",
    "\n",
    "def shuffle_split_data(X, y):\n",
    "    \"\"\" Shuffles and splits data into 75% training and 25% testing subsets,\n",
    "        then returns the training and testing subsets. \"\"\"\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, \n",
    "                                                                        train_size=num_train, random_state=42)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Return the training and testing data subsets\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    X_train, y_train, X_test, y_test = shuffle_split_data(X, y)\n",
    "    print \"Successfully shuffled and split the data!\"\n",
    "except:\n",
    "    print \"Something went wrong with shuffling and splitting the data.\"\n",
    "\n",
    "\n",
    "print \"Training set: {} samples\".format(X_train.shape[0])\n",
    "print \"Test set: {} samples\".format(X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Validating\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created four separate tranches to investigate the data:\n",
    "- All features\n",
    "- A reduced dataset of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X_train\n",
    "\n",
    "seed = 342 # For reproducability\n",
    "folds = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.learning_curve import validation_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "models = {\n",
    "          'XGBoost': XGBClassifier(),\n",
    "          'DecisionTree': DecisionTreeClassifier(),\n",
    "          'SVC': svm.SVC(),\n",
    "          'RandomForest': RandomForestClassifier()\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model_name, model in models.iteritems():\n",
    "    print model_name\n",
    "    kfold = StratifiedKFold(y_train, n_folds=folds, random_state=np.random.seed(seed))\n",
    "    results = cross_val_score(model, X, y_train, cv=kfold, scoring='f1')\n",
    "    print(\"Training data accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100)), '\\n'\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Features_test = X_test\n",
    "\n",
    "for model_name, model in models.iteritems():\n",
    "    print model_name\n",
    "    # make predictions for test data\n",
    "    model.fit(X, y_train)\n",
    "    y_pred = model.predict(Features_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # evaluate predictions\n",
    "    \n",
    "    print \"F1 score: %.3f%%\"% (metrics.f1_score(y_test, predictions))\n",
    "    \n",
    "    C = confusion_matrix(y_test, predictions)\n",
    "    tools.show_confusion_matrix(C, 'report/figures/'+model_name+'.pdf', ['Class Male', 'Class Female'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def visualize_tree(tree, feature_names):\n",
    "    \"\"\"Create tree png using graphviz.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    tree -- scikit-learn DecsisionTree.\n",
    "    feature_names -- list of feature names.\n",
    "    \"\"\"\n",
    "    with open(\"report/figures/dt.dot\", 'w') as f:\n",
    "        export_graphviz(tree, out_file=f, feature_names=feature_names, filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "    command = [\"dot\", \"-Tpng\", \"report/figures/dt.dot\", \"-o\", \"report/figures/dt.png\"]\n",
    "    try:\n",
    "        subprocess.check_call(command)\n",
    "    except:\n",
    "        exit(\"Could not run dot, ie graphviz, to \"\n",
    "             \"produce visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=np.random.seed(seed))\n",
    "dt.fit(X, y_train)\n",
    "\n",
    "visualize_tree(dt, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select XGBoost classifier\n",
    "- Plot first two xgboost trees to see which features were doing the most work of splitting the data\n",
    "- Generate Features from XGBoost classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X, y_train)\n",
    "g = xgb.to_graphviz(model, num_trees=2, rankdir='LR')\n",
    "g.render('report/figures/X_graph', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are just displaying the first two trees here.   \n",
    "\n",
    "On simple models the first two trees may be enough. XGBoost generate `k` trees at each round for a `k`-classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal choices of parameters as taken from Xgboost With Python ebook\n",
    "\n",
    "- Number of Trees (`n_estimators`) set to a fixed value between 100 and 1000, depending on the dataset size.\n",
    "- Learning Rate (`learnin_rate`) simplified to the ratio: [2 to 10]/trees, depending on the trees number of trees.\n",
    "- Row Sampling (`subsample`) grid searched values in the range [0.5, 0.75, 1.0].\n",
    "- Column Sampling (`colsample` bytree and maybe colsample bylevel) grid searched values in the range [0.4, 0.6, 0.8, 1.0].\n",
    "- Min Leaf Weight (`min_child_weight`) simplified to the ratio 3/rare_events , where rare events rare events is the percentage of rare event observations in the dataset.\n",
    "- Tree Size (`max_depth`) grid searched values in the rage [4, 6, 8, 10].\n",
    "- Min Split Gain (`gamma`) fixed with a value of zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "default_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 1,\n",
    "    'learning_rate': 0.3\n",
    "}\n",
    "\n",
    "\n",
    "n_estimators_range = np.linspace(1, 200, 10).astype('int') \n",
    "\n",
    "# Build a stratified shuffle object because of unbalanced data\n",
    "folds = 50\n",
    "ssscv = StratifiedShuffleSplit(y_train, folds, random_state=np.random.seed(seed))\n",
    "\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    XGBClassifier(**default_params),\n",
    "    X, y_train,\n",
    "    param_name = 'n_estimators',\n",
    "    param_range = n_estimators_range,\n",
    "    cv=ssscv,\n",
    "    scoring='accuracy'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Show the validation curve plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6), dpi=100)\n",
    "\n",
    "plt.title(\"Validation Curve with XGBoost (eta = 0.3)\")\n",
    "plt.xlabel(\"number of trees\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.4, 1.1)\n",
    "\n",
    "plt.plot(n_estimators_range,\n",
    "             train_scores_mean,\n",
    "             label=\"Training score\",\n",
    "             color=\"r\")\n",
    "\n",
    "plt.plot(n_estimators_range,\n",
    "             test_scores_mean, \n",
    "             label=\"Cross-validation score\",\n",
    "             color=\"g\")\n",
    "\n",
    "plt.fill_between(n_estimators_range, \n",
    "                 train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, \n",
    "                 alpha=0.2, color=\"r\")\n",
    "\n",
    "plt.fill_between(n_estimators_range,\n",
    "                 test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std,\n",
    "                 alpha=0.2, color=\"g\")\n",
    "\n",
    "plt.axhline(y=1, color='k', ls='dashed')\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "i = np.argmax(test_scores_mean)\n",
    "print(\"Best cross-validation result ({0:.2f}) obtained for {1} trees\".format(test_scores_mean[i], \n",
    "                                                                             n_estimators_range[i]))\n",
    "\n",
    "fig.savefig('report/figures/varianceCurve_1.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plot we can draw the following conclusions:\n",
    "- training score keeps growing while adding new trees, but from a certain point CV score is fixed\n",
    "- variance is lowest, and bias is high for less than 25 trees,\n",
    "- we can see that the model is quite stable keeping variance fixed when increasing it's complexity   \n",
    "\n",
    "We can assume that the trade-off for our model will be met at n_estimators = 50. The variance is still to big.\n",
    "\n",
    "\n",
    "Tweak parameters\n",
    "- To reduce a variance:  \n",
    "    - each tree we will use 70% randomly chosen samples\n",
    "    - 60% randomly chosen features   \n",
    "    \n",
    "- To decrease the bias (bigger accuracy):\n",
    "    - Add an extra level to each tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 2, # changed\n",
    "    'learning_rate': 0.3,\n",
    "    'colsample_bytree': 0.6, # added\n",
    "    'subsample': 0.7 # added\n",
    "}\n",
    "\n",
    "n_estimators_range = np.linspace(1, 200, 10).astype('int')\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    XGBClassifier(**default_params),\n",
    "    X, y_train,\n",
    "    param_name = 'n_estimators',\n",
    "    param_range = n_estimators_range,\n",
    "    cv=ssscv,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6), dpi=100)\n",
    "\n",
    "plt.title(\"Validation Curve with XGBoost (eta = 0.3)\")\n",
    "plt.xlabel(\"number of trees\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.4, 1.1)\n",
    "plt.plot(n_estimators_range,\n",
    "             train_scores_mean,\n",
    "             label=\"Training score\",\n",
    "             color=\"r\")\n",
    "\n",
    "plt.plot(n_estimators_range,\n",
    "             test_scores_mean, \n",
    "             label=\"Cross-validation score\",\n",
    "             color=\"g\")\n",
    "\n",
    "plt.fill_between(n_estimators_range, \n",
    "                 train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, \n",
    "                 alpha=0.2, color=\"r\")\n",
    "\n",
    "plt.fill_between(n_estimators_range,\n",
    "                 test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std,\n",
    "                 alpha=0.2, color=\"g\")\n",
    "\n",
    "plt.axhline(y=1, color='k', ls='dashed')\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "i = np.argmax(test_scores_mean)\n",
    "print(\"Best cross-validation result ({0:.2f}) obtained for {1} trees\".format(test_scores_mean[i], \n",
    "                                                                             n_estimators_range[i]))\n",
    "fig.savefig('report/figures/varianceCurve_2.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "            'learning_rate': [0.2222, 0.4444, 0.6666, 0.8888],\n",
    "            'max_depth': [4, 6, 8, 10],\n",
    "            'n_estimators': range(100, 1100, 100),\n",
    "            'colsample_bytree': [0.6],\n",
    "            'subsample':[0.7]\n",
    "}\n",
    "\n",
    "params_fixed = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load and use already tuned classifier, else tune classifier\n",
    "\n",
    "tune_flag = False\n",
    "\n",
    "if tune_flag:\n",
    "    grid = GridSearchCV(estimator=XGBClassifier(**params_fixed),\n",
    "        param_grid=params_grid,\n",
    "        cv=ssscv,\n",
    "        scoring='f1')\n",
    "    grid.fit(X, y_train)\n",
    "    \n",
    "    print \"Best accuracy obtained: {0}\".format(grid.best_score_)\n",
    "    print \"Parameters:\"\n",
    "    for key, value in grid.best_params_.items():\n",
    "        print \"\\t{}: {}\".format(key, value)\n",
    "    model = grid.best_estimator_\n",
    "    \n",
    "    # save model to file\n",
    "    pickle.dump(model, open(\"genderedCSExperience.pickle.dat\", \"wb\"))\n",
    "    \n",
    "else:    \n",
    "    model = tools.load_model()\n",
    "    print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Features_test = X_test\n",
    "\n",
    "# make predictions for test data\n",
    "model.fit(X, y_train)\n",
    "y_pred = model.predict(Features_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "print \"F1 score: %.2f%%\"% (f1_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X, y_train)\n",
    "g = xgb.to_graphviz(model, num_trees=2, rankdir='LR')\n",
    "g.render('report/figures/Tuned_model_graph', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C = confusion_matrix(y_test, predictions)\n",
    "tools.show_confusion_matrix(C, 'report/figures/tuned_model_CM.pdf', ['Class Male', 'Class Female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
